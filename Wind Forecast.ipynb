{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from fbprophet import Prophet\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from scipy.stats.mstats import mquantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turbine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "df = pd.read_csv(\"data/Turbine_Data.csv\", parse_dates=[\"Unnamed: 0\"], low_memory=False)\n",
    "df['DateTime'] = df['Unnamed: 0'] \n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'], \n",
    " format = '%Y-%m-%dT%H:%M:%SZ', \n",
    " errors = 'coerce')\n",
    "\n",
    "df['year'] = df['DateTime'].dt.year\n",
    "df['month'] = df['DateTime'].dt.month\n",
    "df['day'] = df['DateTime'].dt.day\n",
    "df['hour'] = df['DateTime'].dt.hour\n",
    "df['minute'] = df['DateTime'].dt.minute\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute daily means\n",
    "df_daily = df.copy()\n",
    "df_daily['DateTime'] = df_daily[\"DateTime\"].dt.date\n",
    "df_daily = df_daily[[\"AmbientTemperatue\", \"WindSpeed\", \"DateTime\"]]\n",
    "df_means = df_daily.groupby(\"DateTime\").mean()\n",
    "df_means[\"WindSpeed\"].fillna(method=\"backfill\", inplace=True)\n",
    "df_means[\"AmbientTemperatue\"].fillna(method=\"backfill\", inplace=True)\n",
    "df_means = df_means.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_means[\"WindSpeed\"].values)\n",
    "plt.title(\"Average daily wind speed\", fontsize=16)\n",
    "# plt.savefig(\"wind_data.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Facebook Prophet\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "zero_one_grid = np.linspace(0, 1, 500)\n",
    "\n",
    "prophet1_preds = []\n",
    "prophet2_preds = []\n",
    "prophet3_preds = []\n",
    "prophet4_preds = []\n",
    "dates = []\n",
    "\n",
    "df_prophet = df_means.copy()\n",
    "df_prophet.columns = [\"ds\", \"y\", \"temp\"]\n",
    "df_prophet[\"y\"].fillna(method=\"backfill\", inplace=True)\n",
    "df_prophet[\"temp\"].fillna(method=\"backfill\", inplace=True)\n",
    "\n",
    "offset = 365\n",
    "for i in range(len(df_prophet) - offset - 1):\n",
    "    print(\"\\r {0} / {1}\".format(i + 1, len(df_prophet) - offset - 1), end=\" \", flush=True)\n",
    "    curr_df = df_prophet.iloc[i:(offset + i)]\n",
    "    # no seasonality, no temperature regressor\n",
    "    m1 = Prophet(yearly_seasonality=False)\n",
    "    m1.fit(curr_df)\n",
    "    future = m1.make_future_dataframe(periods=1)\n",
    "    dates.append(future[\"ds\"].values[-1])\n",
    "    \n",
    "    ex = m1.setup_dataframe(future.copy())\n",
    "    samples = m1.sample_posterior_predictive(ex)[\"yhat\"][-1, :]\n",
    "    prophet1_preds.append(mquantiles(samples, zero_one_grid))\n",
    "    \n",
    "    # yes seasonality, no temperature regressor\n",
    "    m2 = Prophet(yearly_seasonality=True)\n",
    "    m2.fit(curr_df)\n",
    "    future = m2.make_future_dataframe(periods=1)\n",
    "    ex = m2.setup_dataframe(future.copy())\n",
    "    samples = m2.sample_posterior_predictive(ex)[\"yhat\"][-1, :]\n",
    "    prophet2_preds.append(mquantiles(samples, zero_one_grid))\n",
    "    \n",
    "    \n",
    "    # no seasonality, yes temperature regressor\n",
    "    m3 = Prophet(yearly_seasonality=False)\n",
    "    m3.add_regressor(\"temp\")\n",
    "    m3.fit(curr_df)\n",
    "    future = m3.make_future_dataframe(periods=1)\n",
    "    future[\"temp\"] = df_prophet[\"temp\"].values[i:(offset + i + 1)]\n",
    "    ex = m3.setup_dataframe(future.copy())\n",
    "    samples = m3.sample_posterior_predictive(ex)[\"yhat\"][-1, :]\n",
    "    prophet3_preds.append(mquantiles(samples, zero_one_grid))\n",
    "    \n",
    "    # yes seasonality, yes temperature regressor\n",
    "    m4 = Prophet(yearly_seasonality=True)\n",
    "    m4.add_regressor(\"temp\")\n",
    "    m4.fit(curr_df)\n",
    "    future = m4.make_future_dataframe(periods=1)\n",
    "    future[\"temp\"] = df_prophet[\"temp\"].values[i:(offset + i + 1)]\n",
    "    ex = m4.setup_dataframe(future.copy())\n",
    "    samples = m4.sample_posterior_predictive(ex)[\"yhat\"][-1, :]\n",
    "    prophet4_preds.append(mquantiles(samples, zero_one_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data/wind_forecasts_new.pickle\", \"wb\") as fp:\n",
    "    pickle.dump({\"grid\": zero_one_grid, \"dates\": dates, \"m1\": prophet1_preds, \n",
    "                 \"m2\": prophet2_preds, \"m3\": prophet3_preds, \"m4\": prophet4_preds}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = m4.predict(future)\n",
    "fig = m4.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct distributions\n",
    "\n",
    "df[\"DateTime\"] = df.DateTime.dt.tz_localize(None)\n",
    "grid_y = np.linspace(0, 1, 100)\n",
    "skip = []\n",
    "\n",
    "Y_quantiles = []\n",
    "for i, date in enumerate(dates):\n",
    "    start = date\n",
    "    end = date + np.timedelta64(1,'D')\n",
    "    daydf = df[(df.DateTime >= start) & (df.DateTime < end)]\n",
    "    if daydf.WindSpeed.isna().sum() > 50:\n",
    "        Y_quantiles.append(None)\n",
    "        skip.append(i)\n",
    "    else:\n",
    "        wind = daydf.WindSpeed.values\n",
    "        wind = wind[~np.isnan(wind)]\n",
    "        Y_quantiles.append(mquantiles(wind, grid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/wind_true.pickle\", \"wb\") as fp:\n",
    "    pickle.dump({\"grid\": grid_y, \"quantiles\": Y_quantiles, \"skip\": skip}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_quantiles[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data/wind_true.pickle\", \"rb\") as fp:\n",
    "    data = pickle.load(fp)\n",
    "    grid_y = data[\"grid\"]\n",
    "    Y_quantiles = data[\"quantiles\"]\n",
    "    skip = data[\"skip\"]\n",
    "\n",
    "    \n",
    "with open(\"data/wind_forecasts.pickle\", \"rb\") as fp:\n",
    "    data = pickle.load(fp)\n",
    "    zero_one_grid = data[\"grid\"]\n",
    "    dates = data[\"dates\"]\n",
    "    prophet1_preds = data[\"m1\"]\n",
    "    prophet2_preds = data[\"m2\"]\n",
    "    prophet3_preds = data[\"m3\"]\n",
    "    prophet4_preds = data[\"m4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pwass.spline import MonotoneQuadraticSplineBasis\n",
    "from pwass.distributions import Distribution\n",
    "from pwass.regression.multi_distrib_on_distrib import MultiDistribOnDistribReg\n",
    "from pwass.regression.distrib_on_distrib import DistribOnDistribReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.empty(len(Y_quantiles), dtype=object)\n",
    "X = np.empty((len(prophet1_preds), 4), dtype=object)\n",
    "spbasis = MonotoneQuadraticSplineBasis(40, zero_one_grid)\n",
    "\n",
    "for i in range(len(Y)):\n",
    "    if i in skip:\n",
    "        continue\n",
    "    \n",
    "    curr_y = Distribution(wbasis=spbasis)\n",
    "    curr_y.init_from_quantile(grid_y, Y_quantiles[i])\n",
    "    curr_y.compute_spline_expansions()\n",
    "    Y[i] = curr_y\n",
    "    \n",
    "    \n",
    "    curr_x = Distribution(wbasis=spbasis)\n",
    "    curr_x.init_from_quantile(zero_one_grid, prophet1_preds[i])\n",
    "    curr_x.compute_spline_expansions()\n",
    "    X[i, 0] = curr_x\n",
    "    \n",
    "    curr_x = Distribution(wbasis=spbasis)\n",
    "    curr_x.init_from_quantile(zero_one_grid, prophet2_preds[i])\n",
    "    curr_x.compute_spline_expansions()\n",
    "    X[i, 1] = curr_x\n",
    "    \n",
    "    curr_x = Distribution(wbasis=spbasis)\n",
    "    curr_x.init_from_quantile(zero_one_grid, prophet3_preds[i])\n",
    "    curr_x.compute_spline_expansions()\n",
    "    X[i, 2] = curr_x\n",
    "    \n",
    "    curr_x = Distribution(wbasis=spbasis)\n",
    "    curr_x.init_from_quantile(zero_one_grid, prophet4_preds[i])\n",
    "    curr_x.compute_spline_expansions()\n",
    "    X[i, 3] = curr_x\n",
    "    \n",
    "skip = np.array(skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.delete(Y, skip)\n",
    "X = np.delete(X, skip, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = X[:-100, :]\n",
    "trainY = Y[:-100]\n",
    "testX = X[-100:, :]\n",
    "testY = Y[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regmulti = MultiDistribOnDistribReg()\n",
    "regp1 = DistribOnDistribReg()\n",
    "regp2 = DistribOnDistribReg()\n",
    "regp3 = DistribOnDistribReg()\n",
    "regp4 = DistribOnDistribReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"lambda_ridge\":[0.5, 1.0, 2.0, 5.0, 10.0, 100.0],\n",
    "              \"spline_basis\": [spbasis],\n",
    "              \"compute_spline\": [False],\n",
    "              \"fit_intercept\": [True, False]}\n",
    "\n",
    "bestp1 = GridSearchCV(regp1, param_grid, cv=10, refit=True)\n",
    "bestp1.fit(trainX[:, 0], trainY)\n",
    "\n",
    "bestp2 = GridSearchCV(regp2, param_grid, cv=10, refit=True)\n",
    "bestp2.fit(trainX[:, 1], trainY)\n",
    "\n",
    "bestp3 = GridSearchCV(regp3, param_grid, cv=10, refit=True)\n",
    "bestp3.fit(trainX[:, 2], trainY)\n",
    "\n",
    "bestp4 = GridSearchCV(regp4, param_grid, cv=10, refit=True)\n",
    "bestp4.fit(trainX[:, 3], trainY)\n",
    "\n",
    "best_multi = GridSearchCV(regmulti, param_grid, cv=10, refit=True)\n",
    "best_multi.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestp1.best_estimator_.score(testX[:, 0], testY, return_sd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestp2.best_estimator_.score(testX[:, 1], testY, return_sd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestp3.best_estimator_.score(testX[:, 2], testY, return_sd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestp4.best_estimator_.score(testX[:, 3], testY, return_sd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_multi.best_estimator_.score(testX, testY, return_sd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_multi.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\n",
    "\n",
    "reg = best_multi.best_estimator_\n",
    "intercept = best_multi.best_params_[\"fit_intercept\"]\n",
    "nbasis = spbasis.nbasis\n",
    "\n",
    "vmin = np.min(reg.beta[intercept:])\n",
    "vmax = np.max(reg.beta[intercept:])\n",
    "\n",
    "for i in range(4):\n",
    "    start = i * nbasis + intercept\n",
    "    end = start + nbasis + 1\n",
    "    betamat = reg.beta[start:end, :]\n",
    "    beta_eval = np.zeros((len(zero_one_grid), len(zero_one_grid)))\n",
    "    for k in range(spbasis.nbasis):\n",
    "        for l in range(spbasis.nbasis):\n",
    "            beta_eval += betamat[k, l] * np.outer(\n",
    "                spbasis.B[k, :], spbasis.B[l, :])\n",
    "    axes[i].imshow(beta_eval, vmin=vmin, vmax=vmax, cmap=\"RdBu_r\", origin='lower') \n",
    "#     axes[i].contourf(beta_eval, vmin=vmin, vmax=vmax, cmap=\"RdBu_r\", \n",
    "#                      levels=np.linspace(-0.15, 0.10, 10))\n",
    "    axes[i].contour(beta_eval, vmin=vmin, vmax=vmax, cmap=\"bwr\", \n",
    "                    levels=np.linspace(-0.15, 0.10, 10))\n",
    "\n",
    "\n",
    "\n",
    "tks = np.arange(0, beta_eval.shape[0] + 1, 100)\n",
    "labs = [\"{0:.1f}\".format(x) for x in np.linspace(0, 1, len(tks))]\n",
    "\n",
    "for i in range(4):\n",
    "    axes[i].set_title(\"beta {0}\".format(i + 1), fontsize=15)\n",
    "    axes[i].set_xticks(tks)\n",
    "    axes[i].set_xticklabels(labs)\n",
    "    axes[i].set_yticks(tks)\n",
    "    axes[i].set_yticklabels(labs)\n",
    "    \n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.82, 0.2, 0.01, 0.6])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "# plt.savefig(\"beta.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = reg.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(spbasis.xgrid, spbasis.eval_spline(reg.beta[0, :]), label=\"alpha\")\n",
    "axes[0].legend(loc=\"lower center\", fontsize=14, bbox_to_anchor=(0.5, -0.3))\n",
    "\n",
    "axes[1].plot(testY[idx].quantile_grid, testY[idx].quantile_eval, lw=3, color=\"steelblue\", label=\"observed\")\n",
    "axes[1].plot(predY[idx].quantile_grid, predY[idx].quantile_eval, lw=3, color=\"orange\", label=\"predicted\")\n",
    "axes[1].plot(testX[idx][0].quantile_grid, testX[idx][0].quantile_eval, color=\"forestgreen\", \n",
    "         alpha=0.8, label=\"M1\")\n",
    "axes[1].plot(testX[idx][1].quantile_grid, testX[idx][1].quantile_eval, \"-.\", color=\"seagreen\", \n",
    "         alpha=0.8, label=\"M2\")\n",
    "axes[1].plot(testX[idx][2].quantile_grid, testX[idx][2].quantile_eval, \".\", color=\"limegreen\", \n",
    "         alpha=0.8, label=\"M3\")\n",
    "axes[1].plot(testX[idx][3].quantile_grid, testX[idx][3].quantile_eval, \"--\", color=\"green\", \n",
    "         alpha=0.8, label=\"M4\")\n",
    "\n",
    "axes[1].legend(ncol=3, loc=\"lower center\", fontsize=14, bbox_to_anchor=(0.5, -0.35))\n",
    "axes[1].set_ylim(-2, 11)\n",
    "plt.savefig(\"alpha_and_wind_pred.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
